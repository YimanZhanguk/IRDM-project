{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import warnings; warnings.filterwarnings(\"ignore\");\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "df_train = pd.read_csv('/Users/zhangyiman/Desktop/train.csv',encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('/Users/zhangyiman/Desktop/test.csv',encoding=\"ISO-8859-1\")\n",
    "df_attr = pd.read_csv('/Users/zhangyiman/Desktop/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('/Users/zhangyiman/Desktop/product_descriptions.csv',encoding=\"ISO-8859-1\")\n",
    "\n",
    "num_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_whole_word(str1, str2, i_):\n",
    "    cnt = 0\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_) \n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class regvalues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, hidden):\n",
    "        dropcols=['id','relevance','search_term','product_title','product_description','product_info','attr','brand']\n",
    "        hidden = hidden.drop(dropcols,axis=1).values\n",
    "        return hidden\n",
    "    \n",
    "class regvalues1(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, hidden):\n",
    "        dropcols=['id','relevance','product_uid','search_term','product_title','product_description','product_info','attr','brand']\n",
    "        hidden = hidden.drop(dropcols,axis=1).values\n",
    "        return hidden\n",
    "\n",
    "class txtcolumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = list(df_attr.name)\n",
    "import re\n",
    "from fuzzyfinder import fuzzyfinder\n",
    "#suggestions = fuzzyfinder('material', L)\n",
    "def fuzzyfinder(user_input, collection):\n",
    "        suggestions =[]\n",
    "        pattern = '.*'.join(user_input) # Converts 'djm' to 'd.*j.*m'\n",
    "        regex = re.compile(pattern)     # Compiles a regex.\n",
    "        for item in collection:\n",
    "            match = regex.search(str(item))  # Checks if the current item matches the regex.\n",
    "            if match:\n",
    "                #suggestions.append((match.start(), item))\n",
    "                suggestions.append(item)\n",
    "        return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strNum = {'zero':0,'one':1,'two':2,'three':3,'four':4,'five':5,'six':6,'seven':7,'eight':8,'nine':9}\n",
    "\n",
    "def str_stem(s): \n",
    "    if isinstance(s, str):\n",
    "        s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n",
    "        s = s.lower()\n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = s.replace(\",\",\"\") #could be number / segment later\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"//\",\"/\")\n",
    "        s = s.replace(\"..\",\".\")\n",
    "        s = s.replace(\" / \",\" \")\n",
    "        s = s.replace(\" \\\\ \",\" \")\n",
    "        s = s.replace(\".\",\" . \")\n",
    "        s = re.sub(r\"(^\\.|/)\", r\"\", s)\n",
    "        s = re.sub(r\"(\\.|/)$\", r\"\", s)\n",
    "        s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "        s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "        s = s.replace(\" x \",\" xbi \")\n",
    "        s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = s.replace(\"*\",\" xbi \")\n",
    "        s = s.replace(\" by \",\" xbi \")\n",
    "        s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "        s = s.replace(\"°\",\" degrees \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "        s = s.replace(\" v \",\" volts \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = s.replace(\" . \",\" \")\n",
    "        #s = (\" \").join([z for z in s.split(\" \") if z not in stop_w])\n",
    "        s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "        \n",
    "        s = s.lower()\n",
    "        s = s.replace(\"toliet\",\"toilet\")\n",
    "        s = s.replace(\"airconditioner\",\"air conditioner\")\n",
    "        s = s.replace(\"vinal\",\"vinyl\")\n",
    "        s = s.replace(\"vynal\",\"vinyl\")\n",
    "        s = s.replace(\"skill\",\"skil\")\n",
    "        s = s.replace(\"snowbl\",\"snow bl\")\n",
    "        s = s.replace(\"plexigla\",\"plexi gla\")\n",
    "        s = s.replace(\"rustoleum\",\"rust-oleum\")\n",
    "        s = s.replace(\"whirpool\",\"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolga\", \"whirlpool ga\")\n",
    "        s = s.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n",
    "        return s\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract new features from attr.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100002.0</td>\n",
       "      <td>BEHR Premium Textured DeckOver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>STERLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>100004.0</td>\n",
       "      <td>Grape Solar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>100005.0</td>\n",
       "      <td>Delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>Whirlpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>Lithonia Lighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>100008.0</td>\n",
       "      <td>Teks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>100009.0</td>\n",
       "      <td>House of Fara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_uid                           brand\n",
       "9       100001.0              Simpson Strong-Tie\n",
       "37      100002.0  BEHR Premium Textured DeckOver\n",
       "69      100003.0                        STERLING\n",
       "93      100004.0                     Grape Solar\n",
       "122     100005.0                           Delta\n",
       "163     100006.0                       Whirlpool\n",
       "204     100007.0               Lithonia Lighting\n",
       "236     100008.0                            Teks\n",
       "256     100009.0                   House of Fara"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\n",
    "df_brand[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>100075.0</td>\n",
       "      <td>Cottage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>100092.0</td>\n",
       "      <td>Cottage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>100117.0</td>\n",
       "      <td>Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6259</th>\n",
       "      <td>100262.0</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_uid    style\n",
       "1784     100075.0  Cottage\n",
       "2290     100092.0  Cottage\n",
       "2936     100117.0  Classic\n",
       "6259     100262.0   Modern"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_lower = fuzzyfinder('product style', collection)\n",
    "style_upper = fuzzyfinder('Product Style', collection)\n",
    "style_lower.extend(style_upper)\n",
    "\n",
    "df_styles = df_attr[df_attr['name'].isin(style_lower)][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"style\"})\n",
    "df_styles=df_styles.drop_duplicates(subset=['product_uid'], keep='first')\n",
    "df_styles[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "colour_lower = fuzzyfinder('Color Family', collection)\n",
    "colour_upper = fuzzyfinder('Color Family', collection)\n",
    "colour_lower.extend(colour_upper)\n",
    "\n",
    "df_colours = df_attr[df_attr['name'].isin(colour_lower)][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"colour\"})\n",
    "df_colours=df_colours.drop_duplicates(subset=['product_uid'], keep='first')\n",
    "#df_colours[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_type = fuzzyfinder('Type', collection)\n",
    "df_type_= fuzzyfinder('type', collection)\n",
    "df_type.extend(df_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>Installation Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>100004.0</td>\n",
       "      <td>Electrical Product Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>100005.0</td>\n",
       "      <td>Bath Faucet Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>Appliance Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>Battery Power Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>100008.0</td>\n",
       "      <td>Fastener Thread Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>100009.0</td>\n",
       "      <td>Moulding Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>100010.0</td>\n",
       "      <td>Landscape Supply Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>100011.0</td>\n",
       "      <td>Drive type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_uid                     type\n",
       "66      100003.0        Installation Type\n",
       "90      100004.0  Electrical Product Type\n",
       "107     100005.0         Bath Faucet Type\n",
       "132     100006.0           Appliance Type\n",
       "180     100007.0       Battery Power Type\n",
       "227     100008.0     Fastener Thread Type\n",
       "259     100009.0            Moulding Type\n",
       "281     100010.0    Landscape Supply Type\n",
       "309     100011.0               Drive type"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_types = df_attr[df_attr['name'].isin(df_type)][[\"product_uid\", \"name\"]].rename(columns={\"name\": \"type\"})\n",
    "df_types=df_types.drop_duplicates(subset=['product_uid'], keep='first')\n",
    "df_types[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>100005.0</td>\n",
       "      <td>Fixed Mount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>100008.0</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>100016.0</td>\n",
       "      <td>Rectangular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>100026.0</td>\n",
       "      <td>Square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_uid        shape\n",
       "130     100005.0  Fixed Mount\n",
       "227     100008.0     Standard\n",
       "444     100016.0  Rectangular\n",
       "666     100026.0       Square"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "shape_lower = fuzzyfinder('shape', collection)\n",
    "shape_upper = fuzzyfinder('Shape', collection)\n",
    "shape_lower.extend(shape_upper)\n",
    "\n",
    "df_shapes = df_attr[df_attr['name'].isin(shape_lower)][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"shape\"})\n",
    "df_shapes=df_shapes.drop_duplicates(subset=['product_uid'], keep='first')\n",
    "df_shapes[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>colour</th>\n",
       "      <th>type</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>Simpson Strong-Tie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deck over</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "      <td>BEHR Premium Textured DeckOver</td>\n",
       "      <td>Cottage</td>\n",
       "      <td>Browns / Tans</td>\n",
       "      <td>Paint Product Type</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Bath Faucet Type</td>\n",
       "      <td>Fixed Mount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Bath Faucet Type</td>\n",
       "      <td>Fixed Mount</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      product_title  product_uid  \\\n",
       "0   2                  Simpson Strong-Tie 12-Gauge Angle       100001   \n",
       "1   3                  Simpson Strong-Tie 12-Gauge Angle       100001   \n",
       "2   9  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...       100002   \n",
       "3  16  Delta Vero 1-Handle Shower Only Faucet Trim Ki...       100005   \n",
       "4  17  Delta Vero 1-Handle Shower Only Faucet Trim Ki...       100005   \n",
       "\n",
       "   relevance         search_term  \\\n",
       "0       3.00       angle bracket   \n",
       "1       2.50           l bracket   \n",
       "2       3.00           deck over   \n",
       "3       2.33    rain shower head   \n",
       "4       2.67  shower only faucet   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Not only do angles make joints stronger, they ...   \n",
       "1  Not only do angles make joints stronger, they ...   \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...   \n",
       "3  Update your bathroom with the Delta Vero Singl...   \n",
       "4  Update your bathroom with the Delta Vero Singl...   \n",
       "\n",
       "                            brand    style         colour                type  \\\n",
       "0              Simpson Strong-Tie      NaN            NaN                 NaN   \n",
       "1              Simpson Strong-Tie      NaN            NaN                 NaN   \n",
       "2  BEHR Premium Textured DeckOver  Cottage  Browns / Tans  Paint Product Type   \n",
       "3                           Delta      NaN         Chrome    Bath Faucet Type   \n",
       "4                           Delta      NaN         Chrome    Bath Faucet Type   \n",
       "\n",
       "         shape  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3  Fixed Mount  \n",
       "4  Fixed Mount  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = df_train.shape[0] #74067\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True) #train+test zongxiangdiejia 240760\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on='product_uid') #240760\n",
    "df_all = pd.merge(df_all, df_styles, how='left', on='product_uid')\n",
    "#df_all = pd.merge(df_all, df_function, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_colours, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_types, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_shapes, how='left', on='product_uid')\n",
    "df_all[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['shape'] = df_all['shape'].map(lambda x:str_stem(x)) \n",
    "df_all['type'] = df_all['type'].map(lambda x:str_stem(x)) \n",
    "df_all['colour'] = df_all['colour'].map(lambda x:str_stem(x)) \n",
    "df_all['style'] = df_all['style'].map(lambda x:str_stem(x)) \n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x)) \n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "df_all['len_of_search'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\n",
    "df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))\n",
    "df_all['query_last_word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[1]))\n",
    "df_all['query_last_word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[2]))\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "df_all['percentage_title'] = df_all['word_in_title']/df_all['len_of_search']\n",
    "df_all['percentage_description'] = df_all['word_in_description']/df_all['len_of_search']\n",
    "df_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']+\"\\t\"+df_all['type']\n",
    "df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_type'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "df_all['percentage_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\n",
    "df_brand = pd.unique(df_all.brand.ravel()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>colour</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>word_in_title</th>\n",
       "      <th>word_in_description</th>\n",
       "      <th>percentage_title</th>\n",
       "      <th>percentage_description</th>\n",
       "      <th>attr</th>\n",
       "      <th>word_in_brand</th>\n",
       "      <th>word_in_type</th>\n",
       "      <th>percentage_brand</th>\n",
       "      <th>brand_feature</th>\n",
       "      <th>search_term_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>simpson strong tie 12 gaug angl</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>not onli do angl make joint stronger they also...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>angl bracket\\tsimpson strong tie\\tnull</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>simpson strong tie 12 gaug angl</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.5</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>not onli do angl make joint stronger they also...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l bracket\\tsimpson strong tie\\tnull</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    product_title  product_uid  relevance   search_term  \\\n",
       "0   2  simpson strong tie 12 gaug angl       100001        3.0  angl bracket   \n",
       "1   3  simpson strong tie 12 gaug angl       100001        2.5     l bracket   \n",
       "\n",
       "                                 product_description               brand  \\\n",
       "0  not onli do angl make joint stronger they also...  simpson strong tie   \n",
       "1  not onli do angl make joint stronger they also...  simpson strong tie   \n",
       "\n",
       "  style colour  type         ...          word_in_title word_in_description  \\\n",
       "0  null   null  null         ...                      1                   1   \n",
       "1  null   null  null         ...                      1                   1   \n",
       "\n",
       "   percentage_title  percentage_description  \\\n",
       "0               0.5                     0.5   \n",
       "1               0.5                     0.5   \n",
       "\n",
       "                                     attr  word_in_brand  word_in_type  \\\n",
       "0  angl bracket\\tsimpson strong tie\\tnull              0             0   \n",
       "1     l bracket\\tsimpson strong tie\\tnull              0             1   \n",
       "\n",
       "   percentage_brand  brand_feature  search_term_feature  \n",
       "0               0.0           1000                   12  \n",
       "1               0.0           1000                    9  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "i = 1000\n",
    "for s in df_brand:\n",
    "    #print(s)\n",
    "    d[s]=i\n",
    "    i+=3\n",
    "#print(d)\n",
    "df_all['brand_feature'] = df_all['brand'].map(lambda x:d[x])\n",
    "df_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x)) #len(x): include the space\n",
    "df_all[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#Set the random seed\n",
    "np.random.seed(12)\n",
    "# Initialize label encoder\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "#encode feature\n",
    "df_all[\"style\"] = label_encoder.fit_transform(df_all[\"style\"])\n",
    "df_all[\"colour\"] = label_encoder.fit_transform(df_all[\"colour\"])\n",
    "df_all[\"type\"] = label_encoder.fit_transform(df_all[\"type\"])\n",
    "df_all[\"shape\"] = label_encoder.fit_transform(df_all[\"shape\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "\n",
    "y_train = df_train['relevance'].values\n",
    "\n",
    "X_train = df_train[:]\n",
    "#X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "\n",
    "X_test = df_test[:]\n",
    "#X_test = df_test.drop(['id','relevance'],axis=1).values\n",
    "#X_train = df_train[:]\n",
    "#X_test = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>colour</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>word_in_title</th>\n",
       "      <th>word_in_description</th>\n",
       "      <th>percentage_title</th>\n",
       "      <th>percentage_description</th>\n",
       "      <th>attr</th>\n",
       "      <th>word_in_brand</th>\n",
       "      <th>word_in_type</th>\n",
       "      <th>percentage_brand</th>\n",
       "      <th>brand_feature</th>\n",
       "      <th>search_term_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>simpson strong tie 12 gaug angl</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>not onli do angl make joint stronger they also...</td>\n",
       "      <td>simpson strong tie</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>l bracket\\tsimpson strong tie\\tnull</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>behr premium textur deckov 1gal. #sc 141 tugbo...</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deck over</td>\n",
       "      <td>behr premium textur deckov is an innov solid c...</td>\n",
       "      <td>behr premium textur deckov</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>deck over\\tbehr premium textur deckov\\tpaint p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1003</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>delta vero 1 handl shower onli faucet trim kit...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>updat your bathroom with the delta vero singl ...</td>\n",
       "      <td>delta</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>rain shower head\\tdelta\\tbath faucet type</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1006</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>delta vero 1 handl shower onli faucet trim kit...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower onli faucet</td>\n",
       "      <td>updat your bathroom with the delta vero singl ...</td>\n",
       "      <td>delta</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>shower onli faucet\\tdelta\\tbath faucet type</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1006</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      product_title  product_uid  \\\n",
       "1   3                    simpson strong tie 12 gaug angl       100001   \n",
       "2   9  behr premium textur deckov 1gal. #sc 141 tugbo...       100002   \n",
       "3  16  delta vero 1 handl shower onli faucet trim kit...       100005   \n",
       "4  17  delta vero 1 handl shower onli faucet trim kit...       100005   \n",
       "\n",
       "   relevance         search_term  \\\n",
       "1       2.50           l bracket   \n",
       "2       3.00           deck over   \n",
       "3       2.33    rain shower head   \n",
       "4       2.67  shower onli faucet   \n",
       "\n",
       "                                 product_description  \\\n",
       "1  not onli do angl make joint stronger they also...   \n",
       "2  behr premium textur deckov is an innov solid c...   \n",
       "3  updat your bathroom with the delta vero singl ...   \n",
       "4  updat your bathroom with the delta vero singl ...   \n",
       "\n",
       "                        brand  style  colour  type         ...           \\\n",
       "1          simpson strong tie      5      77   303         ...            \n",
       "2  behr premium textur deckov      2      27   315         ...            \n",
       "3                       delta      5      45    39         ...            \n",
       "4                       delta      5      45    39         ...            \n",
       "\n",
       "   word_in_title word_in_description  percentage_title  \\\n",
       "1              1                   1          0.500000   \n",
       "2              1                   1          0.500000   \n",
       "3              1                   1          0.333333   \n",
       "4              3                   3          1.000000   \n",
       "\n",
       "   percentage_description                                               attr  \\\n",
       "1                0.500000                l bracket\\tsimpson strong tie\\tnull   \n",
       "2                0.500000  deck over\\tbehr premium textur deckov\\tpaint p...   \n",
       "3                0.333333          rain shower head\\tdelta\\tbath faucet type   \n",
       "4                1.000000        shower onli faucet\\tdelta\\tbath faucet type   \n",
       "\n",
       "   word_in_brand  word_in_type  percentage_brand  brand_feature  \\\n",
       "1              0             1              0.00           1000   \n",
       "2              1             0              0.25           1003   \n",
       "3              0             0              0.00           1006   \n",
       "4              0             1              0.00           1006   \n",
       "\n",
       "   search_term_feature  \n",
       "1                    9  \n",
       "2                    9  \n",
       "3                   16  \n",
       "4                   18  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] rf__max_features=8, rf__max_depth=18 ............................\n",
      "[CV] rf__max_features=8, rf__max_depth=18 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 730 out of 730 | elapsed:   55.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done 730 out of 730 | elapsed:   56.4s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 730 out of 730 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 730 out of 730 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 730 out of 730 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__max_features=8, rf__max_depth=18, score=-0.218606, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 730 out of 730 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__max_features=8, rf__max_depth=18, score=-0.224390, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done 730 out of 730 | elapsed:   56.8s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 730 out of 730 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 18, 'rf__max_features': 8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn import pileline\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "rf = RandomForestRegressor(n_estimators = 730, n_jobs = -1, random_state = 2120, verbose = 1)\n",
    "TFIDF = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')    # sublinear_tf=True, use_idf=True\n",
    "TSVD = TruncatedSVD(n_components=10, random_state = 2016)\n",
    "clf = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                    transformer_list = [\n",
    "                        ('cst',  regvalues()),  \n",
    "                        ('txt1', Pipeline([('s1', txtcolumn(key='search_term')), ('tfidf1', TFIDF), ('tsvd1', TSVD)])),\n",
    "                        ('txt2', Pipeline([('s2', txtcolumn(key='product_title')), ('tfidf2', TFIDF), ('tsvd2', TSVD)])),\n",
    "                        ('txt3', Pipeline([('s3', txtcolumn(key='product_description')), ('tfidf3', TFIDF), ('tsvd3', TSVD)])),\n",
    "                        ('txt4', Pipeline([('s4', txtcolumn(key='brand')), ('tfidf4', TFIDF), ('tsvd4', TSVD)]))\n",
    "                        ],\n",
    "                    transformer_weights = {\n",
    "                        'cst': 1.0,\n",
    "                        'txt1': 0.05,\n",
    "                        'txt2': 0.05,\n",
    "                        'txt3': 0.05,\n",
    "                        'txt4': 0.1\n",
    "                        },\n",
    "                #n_jobs = -1\n",
    "                              )\n",
    "        ), ('rf', rf)   ])\n",
    "param_grid = {'rf__max_features': [8], 'rf__max_depth': [18]}\n",
    "#param_grid = {'rf__max_features': [8], 'rf__max_depth': [18], 'rf__n_estimators':[732,733],'rf__random_state':[2115,2120,2125,2130]}\n",
    "#param_grid = {'rf__max_features': [8], 'rf__max_depth': [18], 'rf__random_state':[2016,1900,2100]}\n",
    "#param_grid = {'rf__max_features': [8], 'rf__max_depth': [18],'rf__n_estimators':[725,727,730,733]}\n",
    "#param_grid = {'rf__max_features': [8], 'rf__max_depth': [18]}\n",
    "rfbest = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 2, verbose = 20,scoring='neg_mean_squared_error')\n",
    "rfbest.fit(X_train, y_train)\n",
    "y_predrf = rfbest.predict(X_test)\n",
    "rfbest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] nn__alpha=0.0001, nn__hidden_layer_sizes=(10, 5) ................\n",
      "[CV] nn__alpha=0.0001, nn__hidden_layer_sizes=(10, 5) ................\n",
      "[CV] nn__alpha=1e-05, nn__hidden_layer_sizes=(10, 5) .................\n",
      "[CV] nn__alpha=1e-05, nn__hidden_layer_sizes=(10, 5) .................\n",
      "[CV]  nn__alpha=0.0001, nn__hidden_layer_sizes=(10, 5), score=-0.252056 -  30.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   34.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  nn__alpha=0.0001, nn__hidden_layer_sizes=(10, 5), score=-0.251428 -  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:   35.0s remaining:   35.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  nn__alpha=1e-05, nn__hidden_layer_sizes=(10, 5), score=-0.251369 -  29.6s\n",
      "[CV]  nn__alpha=1e-05, nn__hidden_layer_sizes=(10, 5), score=-0.255670 -  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   39.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   39.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nn__alpha': 0.0001, 'nn__hidden_layer_sizes': (10, 5)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import pipeline,grid_search\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nn = MLPRegressor(hidden_layer_sizes=(10, 5),  alpha=0.0001, random_state=2050, batch_size=171)\n",
    "TFIDF1 = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')    # sublinear_tf=True, use_idf=True\n",
    "TSVD1 = TruncatedSVD(n_components=10, random_state = 2016)\n",
    "nnclf = pipeline.Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                    transformer_list = [\n",
    "                        ('cst',  regvalues1()),  \n",
    "                        ('txt1', pipeline.Pipeline([('s1', txtcolumn(key='search_term')), ('tfidf1', TFIDF1), ('tsvd1', TSVD1)])),\n",
    "                        ('txt2', pipeline.Pipeline([('s2', txtcolumn(key='product_title')), ('tfidf2', TFIDF1), ('tsvd2', TSVD1)])),\n",
    "                        ('txt3', pipeline.Pipeline([('s3', txtcolumn(key='product_description')), ('tfidf3', TFIDF1), ('tsvd3', TSVD1)])),\n",
    "                        ('txt4', pipeline.Pipeline([('s4', txtcolumn(key='brand')), ('tfidf4', TFIDF1), ('tsvd4', TSVD1)]))\n",
    "                        ],\n",
    "                    transformer_weights = {\n",
    "                        'cst': 1.0,\n",
    "                        'txt1': 0.05,\n",
    "                        'txt2': 0.05,\n",
    "                        'txt3': 0.05,\n",
    "                        'txt4': 0.01\n",
    "                        },\n",
    "                #n_jobs = -1\n",
    "                              )\n",
    "        ), ('nn', nn)   ])\n",
    "#nnparam_grid = {'nn__hidden_layer_sizes':[(10,3),(10,5)], 'nn__alpha':[1e-5, 1e-3]} #add more\n",
    "#nnparam_grid = {'nn__hidden_layer_sizes':[(10,3),(10,5)], 'nn__alpha':[1e-4, 1e-5,1e-6], 'nn__batch_size':[150,160,170,180]} #add more\n",
    "nnparam_grid = {'nn__hidden_layer_sizes':[(10,5)], 'nn__alpha':[1e-4, 1e-5]}\n",
    "#nnparam_grid = {'nn__hidden_layer_sizes':[(10,3),(10,5)], 'nn__alpha':[1e-4,1e-5],'nn__batch_size':[167,168,169,170,171,172,173],'nn__random_state':[2000,2050,2100,2150,2200]}\n",
    "\n",
    "nnbest = grid_search.GridSearchCV(estimator = nnclf, param_grid = nnparam_grid, n_jobs = -1, cv = 2, verbose = 20, scoring='neg_mean_squared_error')\n",
    "nnbest.fit(X_train, y_train)\n",
    "y_prednn = nnbest.predict(X_test)\n",
    "nnbest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = 0.9*y_predrf +0.1*y_prednn\n",
    "df_sol = pd.read_csv('/Users/zhangyiman/Desktop/solution.csv', encoding=\"ISO-8859-1\")\n",
    "df_sol['pred'] = y_pred\n",
    "df_fliter = df_sol[df_sol.Usage == \"Public\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47154933331984566"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "mse = mean_squared_error(df_fliter.relevance, df_fliter.pred, sample_weight=None, multioutput='uniform_average')\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224835163548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2 = r2_score(df_fliter.relevance, df_fliter.pred)  \n",
    "print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#score_rf = cross_val_score(clf,X_train,y_train,cv=5,scoring='mean_squared_error')\n",
    "#score_nn = cross_val_score(nn,X_train,y_train,cv=5,scoring='mean_squared_error')\n",
    "#score = 0.5*(score_rf + score_nn)\n",
    "#score.mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
